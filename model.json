{"format": "layers-model", "generatedBy": "keras v2.4.0", "convertedBy": "TensorFlow.js Converter v3.3.0", "modelTopology": {"keras_version": "2.4.0", "backend": "tensorflow", "model_config": {"class_name": "Functional", "config": {"name": "model_3", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, 1024, 64], "dtype": "float32", "sparse": false, "ragged": false, "name": "input_22"}, "name": "input_22", "inbound_nodes": []}, {"class_name": "InputLayer", "config": {"batch_input_shape": [null, 1024, 64], "dtype": "float32", "sparse": false, "ragged": false, "name": "input_23"}, "name": "input_23", "inbound_nodes": []}, {"class_name": "InputLayer", "config": {"batch_input_shape": [null, 1024, 64], "dtype": "float32", "sparse": false, "ragged": false, "name": "input_24"}, "name": "input_24", "inbound_nodes": []}, {"class_name": "LinearAttention", "config": {"name": "linear_attention_5", "trainable": true, "dtype": "float32"}, "name": "linear_attention_5", "inbound_nodes": [[["input_22", 0, 0, {"K": ["input_23", 0, 0], "V": ["input_24", 0, 0]}]]]}], "input_layers": [["input_22", 0, 0], ["input_23", 0, 0], ["input_24", 0, 0]], "output_layers": [["linear_attention_5", 0, 0]]}}}, "weightsManifest": [{"paths": ["group1-shard1of1.bin"], "weights": [{"name": "linear_attention_5/dense_7/kernel", "shape": [1024, 64], "dtype": "float32"}, {"name": "linear_attention_5/dense_7/bias", "shape": [64], "dtype": "float32"}]}]}